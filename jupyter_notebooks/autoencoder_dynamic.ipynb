{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Dense, GaussianNoise,Lambda,Dropout\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras import backend as K\n",
    "import time\n",
    "# for reproducing result\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 4 k: 2 n: 2\n"
     ]
    }
   ],
   "source": [
    "# defining parameters\n",
    "# define (n,k) here for (n,k) autoencoder\n",
    "# n = n_channel \n",
    "# k = log2(M)  ==> so for (7,4) autoencoder n_channel = 7 and M = 2^4 = 16 \n",
    "M = 4\n",
    "k = np.log2(M)\n",
    "k = int(k)\n",
    "n_channel = 2\n",
    "R = k/n_channel\n",
    "print ('M:',M,'k:',k,'n:',n_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating data of size N\n",
    "N = 8000\n",
    "label = np.random.randint(M,size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating one hot encoded vectors\n",
    "data = []\n",
    "for i in label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 4)\n"
     ]
    }
   ],
   "source": [
    "# checking data shape\n",
    "data = np.array(data)\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [0. 1. 0. 0.]\n",
      "0 [1. 0. 0. 0.]\n",
      "1 [0. 1. 0. 0.]\n",
      "3 [0. 0. 0. 1.]\n",
      "1 [0. 1. 0. 0.]\n",
      "3 [0. 0. 0. 1.]\n",
      "0 [1. 0. 0. 0.]\n",
      "3 [0. 0. 0. 1.]\n",
      "0 [1. 0. 0. 0.]\n",
      "1 [0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# checking generated data with it's label\n",
    "temp_check = [17,23,45,67,89,96,72,250,350, 100]\n",
    "for i in temp_check:\n",
    "    print(label[i],data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining autoencoder and it's layer\n",
    "input_signal = Input(shape=(M,))\n",
    "encoded = Dense(M, activation='relu')(input_signal)\n",
    "encoded1 = Dense(n_channel, activation='linear')(encoded)\n",
    "encoded2 = Lambda(lambda x: np.sqrt(n_channel)*\\\n",
    "                  K.l2_normalize(x,axis=1))(encoded1)\n",
    "\n",
    "EbNo_train = 5.01187 #  coverted 7 db of EbNo\n",
    "encoded3 = GaussianNoise(np.sqrt(1/(2*R*EbNo_train)))(encoded2)\n",
    "\n",
    "decoded = Dense(M, activation='relu')(encoded3)\n",
    "decoded1 = Dense(M, activation='softmax')(decoded)\n",
    "autoencoder = Model(input_signal, decoded1)\n",
    "adam = Adam(lr=0.01)\n",
    "autoencoder.compile(optimizer=adam, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise_2 (GaussianNo (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 20        \n",
      "=================================================================\n",
      "Total params: 62\n",
      "Trainable params: 62\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# printing summary of layers and it's trainable parameters \n",
    "print (autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tensor board visualization\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.3975\n",
      "Epoch 2/45\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.0183\n",
      "Epoch 3/45\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.0120\n",
      "Epoch 4/45\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.0099\n",
      "Epoch 5/45\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.0068\n",
      "Epoch 6/45\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.0083\n",
      "Epoch 7/45\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.0058\n",
      "Epoch 8/45\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.0089\n",
      "Epoch 9/45\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.0085\n",
      "Epoch 10/45\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.0049\n",
      "Epoch 11/45\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.0052\n",
      "Epoch 12/45\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.0059\n",
      "Epoch 13/45\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.0064\n",
      "Epoch 14/45\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.0089\n",
      "Epoch 15/45\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.0075\n",
      "Epoch 16/45\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.0063\n",
      "Epoch 17/45\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.0052\n",
      "Epoch 18/45\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.0086\n",
      "Epoch 19/45\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.0061\n",
      "Epoch 20/45\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.0079\n",
      "Epoch 21/45\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.0039\n",
      "Epoch 22/45\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.0059\n",
      "Epoch 23/45\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.0068\n",
      "Epoch 24/45\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.0049\n",
      "Epoch 25/45\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.0092\n",
      "Epoch 26/45\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.0065\n",
      "Epoch 27/45\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.0039\n",
      "Epoch 28/45\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.0024\n",
      "Epoch 29/45\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.0067\n",
      "Epoch 30/45\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.0070\n",
      "Epoch 31/45\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.0068\n",
      "Epoch 32/45\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.0042\n",
      "Epoch 33/45\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.0049\n",
      "Epoch 34/45\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.0096\n",
      "Epoch 35/45\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.0040\n",
      "Epoch 36/45\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.0062\n",
      "Epoch 37/45\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.0046\n",
      "Epoch 38/45\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.0062\n",
      "Epoch 39/45\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.0094\n",
      "Epoch 40/45\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.0067\n",
      "Epoch 41/45\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.0061\n",
      "Epoch 42/45\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.0060\n",
      "Epoch 43/45\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.0049\n",
      "Epoch 44/45\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.0064\n",
      "Epoch 45/45\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.0044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2909b57f28>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train autoencoder\n",
    "autoencoder.fit(data, data,\n",
    "                epochs=45,\n",
    "                batch_size=32,\n",
    "                callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving keras model\n",
    "from keras.models import load_model\n",
    "# if you want to save model then remove below comment\n",
    "autoencoder.save('autoencoder_v_best.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights(net):\n",
    "    for layer in range(0, len(net.layers)):\n",
    "        #tf.summary.histogram(\"weights_\" + str(layer), net.layers[layer].get_weights()[0])\n",
    "        print('shape of layer #', layer, ' is : ', len(net.layers[layer].get_weights()))\n",
    "        for idx in range(0, len(net.layers[layer].get_weights())):\n",
    "            print('weights layer #', layer, ' index # ', idx)\n",
    "            print(net.layers[layer].get_weights()[idx])\n",
    "            print('')\n",
    "        print('------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "*****************************************************************\n",
      "shape of layer # 0  is :  0\n",
      "------------------------------\n",
      "shape of layer # 1  is :  2\n",
      "weights layer # 1  index #  0\n",
      "[[-0.86180604  1.0006561   0.03171489 -0.5137545 ]\n",
      " [-0.89217997 -0.51101834 -0.5136323  -0.5274368 ]\n",
      " [-0.7181226   0.4323172  -0.29236335  2.220187  ]\n",
      " [ 2.5451448  -0.38080943 -0.58267784  0.23169737]]\n",
      "\n",
      "weights layer # 1  index #  1\n",
      "[ 0.42235565  0.20103526 -0.182984    0.33048078]\n",
      "\n",
      "------------------------------\n",
      "shape of layer # 2  is :  2\n",
      "weights layer # 2  index #  0\n",
      "[[ 1.4573106   0.9288203 ]\n",
      " [-0.91954935 -0.7480976 ]\n",
      " [ 0.74398834  0.02760384]\n",
      " [-0.780783    1.470434  ]]\n",
      "\n",
      "weights layer # 2  index #  1\n",
      "[ 0.05874404 -0.07505464]\n",
      "\n",
      "------------------------------\n",
      "shape of layer # 3  is :  0\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# making encoder from full autoencoder\n",
    "encoder = Model(input_signal, encoded2)\n",
    "print (encoder.summary())\n",
    "print('*****************************************************************')\n",
    "print_weights(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 20        \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "*****************************************************************\n",
      "shape of layer # 0  is :  0\n",
      "------------------------------\n",
      "shape of layer # 1  is :  2\n",
      "weights layer # 1  index #  0\n",
      "[[ 2.5934687  -3.3166964   1.6610289  -0.78468263]\n",
      " [ 0.5585344   0.6446199  -2.279601   -4.1293836 ]]\n",
      "\n",
      "weights layer # 1  index #  1\n",
      "[ 1.6403215   1.3777707  -0.23649213  1.4017253 ]\n",
      "\n",
      "------------------------------\n",
      "shape of layer # 2  is :  2\n",
      "weights layer # 2  index #  0\n",
      "[[-2.8845317  -0.01681621 -1.1837201   1.8193358 ]\n",
      " [ 0.7844021  -3.5271823   1.9074428  -1.9592888 ]\n",
      " [-1.1639773   1.1081109  -0.00977765 -2.2254815 ]\n",
      " [ 2.4161987   1.7562294  -2.737889   -2.2177896 ]]\n",
      "\n",
      "weights layer # 2  index #  1\n",
      "[-1.9333376  -0.5183393   1.5173025   0.75865144]\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# making decoder from full autoencoder\n",
    "encoded_input = Input(shape=(n_channel,))\n",
    "\n",
    "deco = autoencoder.layers[-2](encoded_input)\n",
    "deco = autoencoder.layers[-1](deco)\n",
    "decoder = Model(encoded_input, deco)\n",
    "print (decoder.summary())\n",
    "print('*****************************************************************')\n",
    "print_weights(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frange(x, y, jump):\n",
    "  while x < y:\n",
    "    yield x\n",
    "    x += jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates N symbols. Can be either:\n",
    "# [ 1 0 0 0 ] or\n",
    "# [ 0 1 0 0 ] or\n",
    "# [ 0 0 1 0 ] or\n",
    "# [ 0 0 0 1 ]\n",
    "def generate_random_data(N):\n",
    "    test_label = np.random.randint(4, size=N)\n",
    "    test_data = []\n",
    "    for i in test_label:\n",
    "        temp = np.zeros(4)\n",
    "        temp[i] = 1\n",
    "        test_data.append(temp)\n",
    "    test_data = np.array(test_data)\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constelation diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0 : [1. 0. 0. 0.]\n",
      "[[-1.0350922 -0.9636306]]\n",
      "power: 0.9999999828857289\n",
      "========================\n",
      "i = 1 : [0. 1. 0. 0.]\n",
      "[[ 0.87164336 -1.1136597 ]]\n",
      "power: 1.000000067179426\n",
      "========================\n",
      "i = 2 : [0. 0. 1. 0.]\n",
      "[[-0.8736312  1.112101 ]]\n",
      "power: 0.9999999828857289\n",
      "========================\n",
      "i = 3 : [0. 0. 0. 1.]\n",
      "[[1.0567629  0.93981504]]\n",
      "power: 1.000000067179426\n",
      "========================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ploting constellation diagram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scatter_plot = []\n",
    "for i in range(0,M):\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    print(\"i = \" + str(i) + \" : \" + str(temp))\n",
    "    expand_dims_ = np.expand_dims(temp,axis=0)\n",
    "    prediction = encoder.predict(expand_dims_)\n",
    "    print(prediction)\n",
    "    scatter_plot.append(prediction)\n",
    "    print('power:', np.linalg.norm(prediction)/np.sqrt(n_channel))\n",
    "    print(\"========================\")\n",
    "scatter_plot = np.array(scatter_plot)\n",
    "\n",
    "scatter_plot = scatter_plot.reshape(M,2,1)\n",
    "plt.scatter(scatter_plot[:,0],scatter_plot[:,1])\n",
    "#plt.axis((-2.5,2.5,-2.5,2.5))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BER vs. SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure overhead total time = 1.0269941412843764us\n",
      "TX total time = 1013.6519650041009ms\n",
      "RX total time = 1031.8775970008573ms\n",
      "R         : 1.0\n",
      "Eb/No     : 1.0\n",
      "Eb/No[db] : 0\n",
      "noise_std : 0.7071067811865476\n",
      "dist      : 1.0415544671094703\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 1\n",
      "RX[0] i,q : [ 1.05577461 -0.10173895]\n",
      "\n",
      "dist      : 0.9734950935610429\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 1\n",
      "RX[1] i,q : [ 1.72607578 -1.58017655]\n",
      "SNR: 0 BER: 0.15342\n",
      "=================================================\n",
      "Measure overhead total time = 0.7689959602430463us\n",
      "TX total time = 1015.5670030071633ms\n",
      "RX total time = 1003.496201003145ms\n",
      "R         : 1.0\n",
      "Eb/No     : 1.1220184543019633\n",
      "Eb/No[db] : 0.5\n",
      "noise_std : 0.6675518474746908\n",
      "dist      : 1.0186739909170819\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 3\n",
      "RX[0] i,q : [0.29289085 1.6137558 ]\n",
      "\n",
      "dist      : 0.6934302567194355\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 1\n",
      "RX[1] i,q : [ 0.8820965 -1.8070112]\n",
      "SNR: 0.5 BER: 0.13124\n",
      "=================================================\n",
      "Measure overhead total time = 0.8440038072876632us\n",
      "TX total time = 975.8904179980163ms\n",
      "RX total time = 1014.0279339975677ms\n",
      "R         : 1.0\n",
      "Eb/No     : 1.2589254117941673\n",
      "Eb/No[db] : 1.0\n",
      "noise_std : 0.6302095820932436\n",
      "dist      : 0.9131688193168794\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 3\n",
      "RX[0] i,q : [0.16301882 0.75246844]\n",
      "\n",
      "dist      : 0.46519513771381427\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 1\n",
      "RX[1] i,q : [ 0.79755921 -0.65440158]\n",
      "SNR: 1.0 BER: 0.11018\n",
      "=================================================\n",
      "Measure overhead total time = 1.2279997463338077us\n",
      "TX total time = 1148.6118760003592ms\n",
      "RX total time = 1001.2454539973987ms\n",
      "R         : 1.0\n",
      "Eb/No     : 1.4125375446227544\n",
      "Eb/No[db] : 1.5\n",
      "noise_std : 0.5949562103147331\n",
      "dist      : 0.37290997856497216\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 3\n",
      "RX[0] i,q : [0.79832814 1.208652  ]\n",
      "\n",
      "dist      : 0.5231698825642812\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 1\n",
      "RX[1] i,q : [ 0.60093138 -0.66597487]\n",
      "SNR: 1.5 BER: 0.09284\n",
      "=================================================\n",
      "Measure overhead total time = 0.5879992386326194us\n",
      "TX total time = 989.8843539995141ms\n",
      "RX total time = 987.9148809995968ms\n",
      "R         : 1.0\n",
      "Eb/No     : 1.5848931924611136\n",
      "Eb/No[db] : 2.0\n",
      "noise_std : 0.5616748812614791\n",
      "dist      : 1.272301110181463\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 3\n",
      "RX[0] i,q : [0.04802549 0.16444489]\n",
      "\n",
      "dist      : 0.721852281555278\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 1\n",
      "RX[1] i,q : [ 0.94280199 -1.83199613]\n",
      "SNR: 2.0 BER: 0.07338\n",
      "=================================================\n",
      "Measure overhead total time = 1.0080038919113576us\n",
      "TX total time = 988.0350569947041ms\n",
      "RX total time = 1024.7127149923472ms\n",
      "R         : 1.0\n",
      "Eb/No     : 1.7782794100389228\n",
      "Eb/No[db] : 2.5\n",
      "noise_std : 0.530255280591504\n",
      "dist      : 0.19640211956217674\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 3\n",
      "RX[0] i,q : [1.04431969 0.7438075 ]\n",
      "\n",
      "dist      : 0.37808617026888947\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 1\n",
      "RX[1] i,q : [ 0.74962561 -1.47151561]\n",
      "SNR: 2.5 BER: 0.05956\n",
      "=================================================\n",
      "Measure overhead total time = 0.6929985829629004us\n",
      "TX total time = 1127.5045029979083ms\n",
      "RX total time = 1071.1773639995954ms\n",
      "R         : 1.0\n",
      "Eb/No     : 1.9952623149688795\n",
      "Eb/No[db] : 3.0\n",
      "noise_std : 0.5005932648504534\n",
      "dist      : 1.8690826806627563\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 3\n",
      "RX[0] i,q : [2.91442435 0.73350425]\n",
      "\n",
      "dist      : 1.043335410771945\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 0\n",
      "RX[1] i,q : [-0.07732918 -0.6800702 ]\n",
      "SNR: 3.0 BER: 0.04736\n",
      "=================================================\n",
      "Measure overhead total time = 0.5480032996274531us\n",
      "TX total time = 996.5092169950367ms\n",
      "RX total time = 998.2463019914576ms\n",
      "R         : 1.0\n",
      "Eb/No     : 2.2387211385683394\n",
      "Eb/No[db] : 3.5\n",
      "noise_std : 0.47259051627755033\n",
      "dist      : 1.0353865091603078\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 3\n",
      "RX[0] i,q : [1.92175976 0.37077575]\n",
      "\n",
      "dist      : 0.7451468990555438\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 1\n",
      "RX[1] i,q : [ 1.57513201 -1.35931728]\n",
      "SNR: 3.5 BER: 0.0341\n",
      "=================================================\n",
      "Measure overhead total time = 0.9409995982423425us\n",
      "TX total time = 1030.9557159998803ms\n",
      "RX total time = 949.4614690047456ms\n",
      "R         : 1.0\n",
      "Eb/No     : 2.51188643150958\n",
      "Eb/No[db] : 4.0\n",
      "noise_std : 0.4461542169214011\n",
      "dist      : 0.7316017398893364\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 3\n",
      "RX[0] i,q : [0.88920595 0.22765933]\n",
      "\n",
      "dist      : 0.7519377465242567\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 1\n",
      "RX[1] i,q : [ 1.46122733 -1.58035142]\n",
      "SNR: 4.0 BER: 0.02556\n",
      "=================================================\n",
      "Measure overhead total time = 1.0660005500540137us\n",
      "TX total time = 1073.92240199988ms\n",
      "RX total time = 1062.4521669960814ms\n",
      "R         : 1.0\n",
      "Eb/No     : 2.8183829312644537\n",
      "Eb/No[db] : 4.5\n",
      "noise_std : 0.4211967409854779\n",
      "dist      : 0.6103950563779971\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 3\n",
      "RX[0] i,q : [1.26524631 0.36612802]\n",
      "\n",
      "dist      : 0.190546259113536\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 1\n",
      "RX[1] i,q : [ 0.75448336 -0.96338862]\n",
      "SNR: 4.5 BER: 0.01918\n",
      "=================================================\n",
      "Measure overhead total time = 0.9180002962239087us\n",
      "TX total time = 1116.5274980012327ms\n",
      "RX total time = 1211.8596750005963ms\n",
      "R         : 1.0\n",
      "Eb/No     : 3.1622776601683795\n",
      "Eb/No[db] : 5.0\n",
      "noise_std : 0.3976353643835253\n",
      "dist      : 0.4136124448258073\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 3\n",
      "RX[0] i,q : [1.01873062 1.35167521]\n",
      "\n",
      "dist      : 0.3572071437949374\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 1\n",
      "RX[1] i,q : [ 1.1473463  -0.88653678]\n",
      "SNR: 5.0 BER: 0.01246\n",
      "=================================================\n",
      "Measure overhead total time = 0.7749986252747476us\n",
      "TX total time = 1098.3200939954259ms\n",
      "RX total time = 1042.9459650040371ms\n",
      "R         : 1.0\n",
      "Eb/No     : 3.548133892335755\n",
      "Eb/No[db] : 5.5\n",
      "noise_std : 0.37539199054218336\n",
      "dist      : 0.52266805777203\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 3\n",
      "RX[0] i,q : [0.53499443 0.90916327]\n",
      "\n",
      "dist      : 0.07969470425837677\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 1\n",
      "RX[1] i,q : [ 0.95112051 -1.11954438]\n",
      "SNR: 5.5 BER: 0.00778\n",
      "=================================================\n",
      "Measure overhead total time = 0.8819988579489291us\n",
      "TX total time = 1007.7603830068256ms\n",
      "RX total time = 1004.9216830011574ms\n",
      "R         : 1.0\n",
      "Eb/No     : 3.9810717055349722\n",
      "Eb/No[db] : 6.0\n",
      "noise_std : 0.3543928915419707\n",
      "dist      : 0.6319756713482808\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 3\n",
      "RX[0] i,q : [0.76630573 1.50108847]\n",
      "\n",
      "dist      : 0.49567924460225904\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 1\n",
      "RX[1] i,q : [ 0.59914506 -1.527716  ]\n",
      "SNR: 6.0 BER: 0.00506\n",
      "=================================================\n",
      "Measure overhead total time = 0.7880007615312934us\n",
      "TX total time = 1126.7912469993462ms\n",
      "RX total time = 1107.313714994234ms\n",
      "R         : 1.0\n",
      "Eb/No     : 4.466835921509632\n",
      "Eb/No[db] : 6.5\n",
      "noise_std : 0.33456846373861504\n",
      "dist      : 0.3788926435076488\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 3\n",
      "RX[0] i,q : [0.87318851 0.60836359]\n",
      "\n",
      "dist      : 0.20448548899528343\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 1\n",
      "RX[1] i,q : [ 0.72614093 -1.2573377 ]\n",
      "SNR: 6.5 BER: 0.00322\n",
      "=================================================\n",
      "Measure overhead total time = 0.8549977792426944us\n",
      "TX total time = 1073.3165010024095ms\n",
      "RX total time = 1269.431409004028ms\n",
      "R         : 1.0\n",
      "Eb/No     : 5.011872336272722\n",
      "Eb/No[db] : 7.0\n",
      "noise_std : 0.31585299705471215\n",
      "dist      : 0.33916020458927326\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 3\n",
      "RX[0] i,q : [1.27637176 1.19827512]\n",
      "\n",
      "dist      : 0.8340457828295564\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 1\n",
      "RX[1] i,q : [ 0.3817254  -0.43866881]\n",
      "SNR: 7.0 BER: 0.00186\n",
      "=================================================\n",
      "Measure overhead total time = 0.690997694619us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TX total time = 1167.8530520002823ms\n",
      "RX total time = 1091.613012002199ms\n",
      "R         : 1.0\n",
      "Eb/No     : 5.623413251903491\n",
      "Eb/No[db] : 7.5\n",
      "noise_std : 0.2981844571770067\n",
      "dist      : 0.6881551770373044\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 3\n",
      "RX[0] i,q : [1.22600842 0.27279667]\n",
      "\n",
      "dist      : 0.49362884684671\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 1\n",
      "RX[1] i,q : [ 0.98418899 -1.59428737]\n",
      "SNR: 7.5 BER: 0.00084\n",
      "=================================================\n",
      "Measure overhead total time = 0.6740010576322675us\n",
      "TX total time = 1010.7702370005427ms\n",
      "RX total time = 1130.9939139973721ms\n",
      "R         : 1.0\n",
      "Eb/No     : 6.309573444801933\n",
      "Eb/No[db] : 8.0\n",
      "noise_std : 0.2815042799373673\n",
      "dist      : 0.23664425735674818\n",
      "TX[0] val : 3\n",
      "TX[0] i,q : [1.0567629  0.93981504]\n",
      "RX[0]     : 3\n",
      "RX[0] i,q : [0.85099417 0.82294024]\n",
      "\n",
      "dist      : 0.45387305511149295\n",
      "TX[1] val : 1\n",
      "TX[1] i,q : [ 0.87164336 -1.1136597 ]\n",
      "RX[1]     : 1\n",
      "RX[1] i,q : [ 0.7146809  -1.53952772]\n",
      "SNR: 8.0 BER: 0.00046\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "# calculating BER\n",
    "# this is optimized BER function so it can handle large number of N\n",
    "# previous code has another for loop which was making it slow\n",
    "N = 50000\n",
    "test_data = generate_random_data(N)\n",
    "EbNodB_range = list(frange(0,8.5,0.5))\n",
    "ber = [None]*len(EbNodB_range)\n",
    "for n in range(0,len(EbNodB_range)):\n",
    "    measure_overhead_start_time = perf_counter()\n",
    "    measure_overhead_end_time = perf_counter()\n",
    "    measure_overhead_total_time = measure_overhead_end_time - measure_overhead_start_time\n",
    "    print('Measure overhead total time = ' + str((measure_overhead_total_time)*1000000) + \"us\")\n",
    "    EbNo=10.0**(EbNodB_range[n]/10.0)\n",
    "    noise_std = np.sqrt(1/(2*R*EbNo))\n",
    "    noise_mean = 0\n",
    "    no_errors = 0\n",
    "    noise = noise_std * np.random.randn(N,n_channel)\n",
    "    tx_start_time = perf_counter()\n",
    "    encoded_signal = encoder.predict(test_data)\n",
    "    tx_end_time = perf_counter()\n",
    "    print('TX total time = ' + str((tx_end_time - tx_start_time - measure_overhead_total_time)*1000) + \"ms\")\n",
    "    final_signal = encoded_signal + noise\n",
    "    rx_start_time = perf_counter()\n",
    "    pred_final_signal =  decoder.predict(final_signal)\n",
    "    pred_output = np.argmax(pred_final_signal,axis=1)\n",
    "    rx_end_time = perf_counter()\n",
    "    print('RX total time = ' + str((rx_end_time - rx_start_time - measure_overhead_total_time)*1000) + \"ms\")\n",
    "    print('R         :', R)\n",
    "    print('Eb/No     :', EbNo)\n",
    "    print('Eb/No[db] :', EbNodB_range[n])\n",
    "    print('noise_std :', noise_std)\n",
    "    print('dist      :', np.linalg.norm(encoded_signal[0] - final_signal[0]))\n",
    "    print('TX[0] val :', test_label[0])\n",
    "    print('TX[0] i,q :', encoded_signal[0])\n",
    "    print('RX[0]     :', pred_output[0])\n",
    "    print('RX[0] i,q :', final_signal[0])\n",
    "    print(\"\")\n",
    "    print('dist      :', np.linalg.norm(encoded_signal[1] - final_signal[1]))\n",
    "    print('TX[1] val :', test_label[1])\n",
    "    print('TX[1] i,q :', encoded_signal[1])\n",
    "    print('RX[1]     :', pred_output[1])\n",
    "    print('RX[1] i,q :', final_signal[1])\n",
    "    no_errors = (pred_output != test_label)\n",
    "    no_errors =  no_errors.astype(int).sum()\n",
    "    ber[n] = no_errors / N \n",
    "    print ('SNR:',EbNodB_range[n],'BER:',ber[n])\n",
    "    print('=================================================')\n",
    "    # use below line for generating matlab like matrix which can be copy and paste for plotting ber graph in matlab\n",
    "    #print(ber[n], \" \",end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9027a07fd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ploting ber curve\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "plt.plot(EbNodB_range, ber, 'bo',label='Autoencoder('+str(k)+','+str(n_channel)+')')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('SNR Range')\n",
    "plt.ylabel('Block Error Rate')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right',ncol = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nsymbols = np.floor(np.linspace(10, 1250, 50)).astype(int)\n",
    "Nsymbols = np.concatenate((np.arange(start=10, stop=200, step=50), \n",
    "                           np.arange(start=200, stop=1000, step=100)), axis=0)\n",
    "print(Nsymbols)\n",
    "hw_exec_time_vec = np.zeros(len(Nsymbols))\n",
    "start_time = time.time()\n",
    "stop_time = time.time()\n",
    "measure_self_time = stop_time-start_time\n",
    "\n",
    "for y in range(len(Nsymbols)):\n",
    "    data_in = generate_random_data(Nsymbols[y])\n",
    "    in_buffer = xlnk.cma_array(shape=(len(data_in),), dtype=np.int32)\n",
    "    out_buffer = xlnk.cma_array(shape=(len(data_in),), dtype=np.int32)\n",
    "    np.copyto(in_buffer,data_in)    \n",
    "    start_time = time.time()\n",
    "    dma.sendchannel.transfer(in_buffer)\n",
    "    dma.recvchannel.transfer(out_buffer)\n",
    "    dma.sendchannel.wait()\n",
    "    dma.recvchannel.wait()\n",
    "    stop_time = time.time()\n",
    "    hw_exec_time_vec[y] = (stop_time-start_time-measure_self_time)*1000\n",
    "\n",
    "# Execution time as function of data length\n",
    "plt.plot(Nsymbols, hw_exec_time_vec)\n",
    "plt.xlabel('# Symbols (16 Bytes)')\n",
    "plt.ylabel('Execution time [ms]')\n",
    "plt.grid(True)\n",
    "#print(Nsymbols)\n",
    "#print(hw_exec_time_vec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsymbols = np.concatenate((np.arange(start=10, stop=200, step=50), \n",
    "                           np.arange(start=200, stop=10000, step=100)), axis=0)\n",
    "Ntests = 20\n",
    "\n",
    "sw_exec_time_vec = np.zeros((Ntests, len(Nsymbols)))\n",
    "start_time = time.time()\n",
    "stop_time = time.time()\n",
    "measure_self_time = stop_time-start_time\n",
    "\n",
    "for test_id in range(Ntests):\n",
    "    for y in range(len(Nsymbols)):\n",
    "        data_in = generate_random_data(Nsymbols[y])\n",
    "\n",
    "        tx_start_time = time.time()\n",
    "        encoded_signal = encoder.predict(data_in)\n",
    "        tx_end_time = time.time()\n",
    "        tx_time = (tx_end_time - tx_start_time - measure_self_time)*1000\n",
    "        final_signal = encoded_signal\n",
    "        rx_start_time = time.time()\n",
    "        pred_final_signal =  decoder.predict(final_signal)\n",
    "        pred_output = np.argmax(pred_final_signal,axis=1)\n",
    "        rx_end_time = time.time()\n",
    "        rx_time = (rx_end_time - rx_start_time - measure_self_time)*1000\n",
    "        sw_exec_time_vec[test_id, y] = tx_time + rx_time\n",
    "    #     print(hw_exec_time_vec[y])\n",
    "        # use below line for generating matlab like matrix which can be copy and paste for plotting ber graph in matlab\n",
    "        #print(ber[n], \" \",end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sw_exec_time_vec = np.mean(sw_exec_time_vec, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.33718252,   2.48003006,   4.728055  ,   5.84330559,\n",
       "         8.58491659,  12.78574467,  14.53801394,  18.90070438,\n",
       "        22.55301476,  25.4357934 ,  28.84516716,  32.89698362,\n",
       "        37.28247881,  41.18812084,  42.68226624,  46.46191597,\n",
       "        49.51156378,  52.9309392 ,  58.74325037,  61.30627394,\n",
       "        66.55865908,  68.87162924,  71.54535055,  77.36371756,\n",
       "        82.05834627,  82.76798725,  85.5718255 ,  88.1354332 ,\n",
       "        92.7267909 ,  99.04347658, 103.23832035, 105.39360046,\n",
       "       107.30762482, 110.28927565, 114.98961449, 118.9084053 ,\n",
       "       122.89119959, 124.81124401, 128.98906469, 132.92633295,\n",
       "       134.45657492, 140.55957794, 143.01980734, 148.7409234 ,\n",
       "       150.6405592 , 157.7855587 , 158.46712589, 159.66328382,\n",
       "       166.34050608, 171.93937302, 177.63944864, 174.51050282,\n",
       "       179.4383049 , 186.94297075, 191.83291197, 194.44311857,\n",
       "       203.51091623, 198.85662794, 201.02648735, 205.26673794,\n",
       "       209.74487066, 214.92580175, 216.94688797, 222.54804373,\n",
       "       224.261415  , 223.70918989, 229.85544205, 241.71677828,\n",
       "       244.21242476, 251.25153065, 249.23024178, 255.71408272,\n",
       "       258.42586756, 259.0318203 , 263.97647858, 276.93678141,\n",
       "       273.61328602, 276.53441429, 281.02831841, 285.98189354,\n",
       "       285.96547842, 295.13555765, 292.71230698, 297.64024019,\n",
       "       298.95777702, 301.28616095, 305.00073433, 307.49310255,\n",
       "       313.79945278, 315.30951262, 323.32295179, 325.84770918,\n",
       "       327.21458673, 331.70620203, 336.77486181, 339.91520405,\n",
       "       344.21472549, 342.57872105, 352.11946964, 358.3812356 ,\n",
       "       351.42768621, 362.97090054])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sw_exec_time_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
