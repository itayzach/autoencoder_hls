# Neural Network Inference Acceleration on FPGA
This work is an FPGA implemention of a Physical Layer Deep Learning communications system on a PYNQ Z2 board, based on Xilinx's HLS. This work is a proof of concept for accelerating the inference phase of a Deep Learning system.

* The system implements [An Introduction to Deep Learning for the Physical Layer](https://ieeexplore.ieee.org/document/8054694]) by O'Shea et. al.
* The TensorFlow model used to train this network is based on [immortal3's implementation](https://github.com/immortal3/AutoEncoder-Based-Communication-System)
* The project is based on the [hls4ml](https://hls-fpga-machine-learning.github.io/hls4ml/) package

More information can be found on the PDF report in this repository.
